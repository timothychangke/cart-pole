{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yue-zhongqi/cartpole_colab/blob/main/cartpole.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZauhjPSfX7pI"
      },
      "source": [
        "# Tutorial and Sample Code for Balancing a Pole on a Cart"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RwKbYeTgbaTA"
      },
      "source": [
        "## Importing dependencies and define helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {
        "id": "j6KpgCLGYWmj"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import math\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple, deque\n",
        "from itertools import count\n",
        "from tqdm import tqdm\n",
        "from gym.wrappers import RecordVideo\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2oIzK9SzhlWN"
      },
      "source": [
        "## Task 1: Development of an RL agent"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sDiCxLcXv6aI"
      },
      "source": [
        "### Task 1: Deep Q Network RL Agent ###\n",
        "referenced from https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### DEEP Q-Network (DQN) ####"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Constructor #####\n",
        "\n",
        "__n_observations__ : Size of observation space (input size), number of features observed from environment at each timestamp\n",
        "__n_actions__ : Size of action space (ouput size), number of possible actions the agent can take\n",
        "\n",
        "__self.layer1__ : takes the input (observation) and transforms it into a 128-dimensional space <br>\n",
        "__self.layer2__ : hidden layer which operates on the 128-dimensional space and outputs another 128-dimensional space <br>\n",
        "__self.layer3__ : transforms the output of __layer2__ into the action space size, producing a vlue for each possible action\n",
        "\n",
        "##### Forward Pass #####\n",
        "\n",
        "1. __forward__ takes an input tensor __x__ (observations) \n",
        "2. Passes __x__ through __layer1__ and applies the ReLu activation function (__F.relu__) to the output\n",
        "3. Ouput is then pass through __layer2__ and another ReLu activation function \n",
        "4. Output of __layer2__ is passed through __layer3__ which maps it to the action space and returned without any activation function (output represents expected rewards for each action)<br>\n",
        "\n",
        "Output of __forward__ method is a tensor where each element corresponds to a predicted value (Q-value) of taking an action given the current observation and used by the agent to decide which action to take next\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if CUDA is available, otherwise use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, n_observations, n_actions):\n",
        "        super(DQN, self).__init__()\n",
        "        self.fc1 = nn.Linear(n_observations, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, n_actions)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Replay Memory ####\n",
        "\n",
        "##### Transition #####\n",
        "__Transition__ is a __namedtuple__ which represents a single transition in the environment and is essentially a timestamp of the agent's interaction with the environment and includes:\n",
        "- __state__ : observation of enivronment before taking the action\n",
        "- __action__ : action taken by the agent\n",
        "- __next_state__ : obeservation of environment after taking the action\n",
        "- __reward__ : reward received after taking the action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {},
      "outputs": [],
      "source": [
        "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Constructor #####\n",
        "Takes a single argument __capacity__ which is the maximum number of transitions the replay memory can hold and initialises a __deque__ (double-ended queue) with a fixed maximum length of __capacity__. This __deque__ automatically removes the oldest element when new transitions are added beyond its capacity, ensuring memory size never exceeds the specifieid limit\n",
        "\n",
        "##### Push #####\n",
        "Apends a new __Transition__ object to the __memory__ deque\n",
        "\n",
        "##### Sample #####\n",
        "Randomly samples a batch of transitions from the memory, where __batch_size__ specifies how many transitions to sample, allowing the DQN to learn from a random sample of past experiences, reducing correlation between consecutive training samples and stabilises training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ReplayMemory(object):\n",
        "    def __init__(self, capacity):\n",
        "        self.memory = deque([], maxlen=capacity)\n",
        "\n",
        "    def add(self, *args):\n",
        "        self.memory.append(Transition(*args))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Environment Initialisation ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([-0.04404246,  0.00477466,  0.00630126,  0.03452177], dtype=float32),\n",
              " {})"
            ]
          },
          "execution_count": 276,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env = gym.make('CartPole-v1').unwrapped\n",
        "env.reset()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Hyperparameters #####\n",
        "__BATCH_SIZE__ : Number of training examples used in one iteration to update the network's weights <br>\n",
        "__GAMMA__ : Discount factor for future rewards, influencing how much the agent values immediate rewards over future rewards <br>\n",
        "__EPS_START__, __EPS_END__, __EPS_DECAY__ : Parameters for epsilon-greedy strategy <br>\n",
        "__TAU__ : Parameter used for soft update of the target network's weights <br>\n",
        "__LR__ : Learning rate for optimiser <br>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Network Initialisation #####\n",
        "__n_actions__ & __n_observations__ : Determines size of action space and shape of obervation space respectively"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__policy_net__ : Neural network used to determine action to take at each step"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__target_net__ : A copy of the policy network which helps in stabilising training. It is updated less frequently to provide a stable target for optimising the policy network"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Optimiser #####\n",
        "Defines the optimisation algorithm used to update the weights of the policy network (AdamW). __amsgrad=True__ is a variant of the Adam optimiser which can lead to better convergence in some cases"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Replay Memory #####\n",
        "Initialises replay memory with a caopacity of 10000 transitions"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Steps counter #####\n",
        "Keeps track of the total number of actions the agent has taken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {},
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "GAMMA = 0.99\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 200\n",
        "TAU = 0.005\n",
        "LR = 1e-4\n",
        "\n",
        "n_actions = env.action_space.n\n",
        "n_observations = env.observation_space.shape[0]\n",
        "\n",
        "policy_net = DQN(n_observations, n_actions).to(device)\n",
        "target_net = DQN(n_observations, n_actions).to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n",
        "\n",
        "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
        "memory = ReplayMemory(10000)\n",
        "\n",
        "steps_done = 0"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Optimiser ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {},
      "outputs": [],
      "source": [
        "def optimize_model():\n",
        "    # Checks if there are enough transitions stored in the replay memory to sample a batch.\n",
        "    # If not, returns immediately without performing optimisation\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "    \n",
        "    # Samples a batch of transition from the replay memory and restructures this batch\n",
        "    # Converts the batch from a list of \"Transition\" namedtuples into a single \"Transition\" namedtuple\n",
        "    # where each attribute contain all corresponding elements from the batch\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    batch = Transition(*zip(*transitions))\n",
        "\n",
        "    # Processes the batch to separate final and non-final states\n",
        "    # A mask is created to identify non-final states\n",
        "    # States, actions & rewards concatenated into tensors for batch processing\n",
        "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
        "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                                if s is not None])\n",
        "    state_batch = torch.cat(batch.state)\n",
        "    action_batch = torch.cat(batch.action)\n",
        "    reward_batch = torch.cat(batch.reward)\n",
        "\n",
        "    # Calculates the Q-values predcited by the \"policy_net\" for the actions taken\n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
        "\n",
        "    # Calculates the expected Q-values for the next states using the \"target_net\"\n",
        "    # Only does this for non_final states\n",
        "    # Calculated based on the maximum Q-value predicted for the next states following the Bellman equation\n",
        "    # adjusted by reward received and discount factor (GAMMA)\n",
        "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "    with torch.no_grad():\n",
        "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values\n",
        "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "\n",
        "    # Loss between predicted Q-values \"state_action_values\" and expected Q-values \"expected_state_action_values\"\n",
        "    # computed using the Huber Loss (Smooth L1 Loss)\n",
        "    # which is less sensitive to outliers than squared error loss\n",
        "    criterion = nn.SmoothL1Loss()\n",
        "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "\n",
        "    # Gradient of loss with respect ot network parameters calculated using backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    \n",
        "    # Optimiser updates network parameters based on gradients\n",
        "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
        "    optimizer.step()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Epsilon Greedy Strategy ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BGd9fDa9jX6",
        "outputId": "fd2e5dd4-bcdb-4343-c853-c96b23b95177"
      },
      "outputs": [],
      "source": [
        "def select_action(state):\n",
        "    # Epsilon Threshold Calculation\n",
        "    global steps_done\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done / EPS_DECAY)\n",
        "    steps_done += 1\n",
        "    \n",
        "    # Action Selection\n",
        "    if random.random() > eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            # Select action with highest Q-value\n",
        "            return policy_net(state).max(1)[1].view(1, 1)\n",
        "    else:\n",
        "        # Select random action\n",
        "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Main Training Loop ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [04:03<00:00,  4.10it/s]\n"
          ]
        }
      ],
      "source": [
        "# Constants\n",
        "number_of_episodes = 1000  # For DQN simulation learning\n",
        "gamma = 0.99  # Discount factor\n",
        "epsilon_start = 1.0  # Starting value of epsilon for exploration\n",
        "epsilon_end = 0.01  # Minimum value of epsilon\n",
        "epsilon_decay = 200  # Rate at which to decay epsilon\n",
        "batch_size = 128  # Batch size for replay memory sampling\n",
        "target_update = 10  # How often to update the target network\n",
        "\n",
        "# Initialize environment\n",
        "env = gym.make('CartPole-v1')\n",
        "\n",
        "# Get number of actions and observations from the environment\n",
        "n_actions = env.action_space.n\n",
        "n_observations = env.observation_space.shape[0]\n",
        "\n",
        "# Initialize policy and target networks\n",
        "policy_net = DQN(n_observations, n_actions).to(device)\n",
        "target_net = DQN(n_observations, n_actions).to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()  # Set target net to evaluation mode\n",
        "\n",
        "# Optimizer and Replay Memory\n",
        "optimizer = optim.Adam(policy_net.parameters())\n",
        "memory = ReplayMemory(10000)\n",
        "\n",
        "# Function to update epsilon\n",
        "def epsilon_by_episode(episode):\n",
        "    return epsilon_end + (epsilon_start - epsilon_end) * math.exp(-1. * episode / epsilon_decay)\n",
        "\n",
        "all_episodes_reward = []\n",
        "\n",
        "for episode in tqdm(range(number_of_episodes)):\n",
        "    env_state, _ = env.reset()\n",
        "    state = torch.tensor([env_state], device=device, dtype=torch.float)\n",
        "    total_reward = 0\n",
        "    epsilon = epsilon_by_episode(episode)\n",
        "    done = False\n",
        "    \n",
        "    while not done:\n",
        "        action = select_action(state)\n",
        "        next_state, reward, done, _, _ = env.step(action.item())\n",
        "        total_reward += reward\n",
        "        \n",
        "        if total_reward > 500:  # Condition to stop the episode if reward exceeds 500\n",
        "            break  # Breaks out of the while loop, ending the episode\n",
        "        \n",
        "        if not done:\n",
        "            next_state_tensor = torch.tensor([next_state], device=device, dtype=torch.float)\n",
        "        else:\n",
        "            next_state_tensor = None\n",
        "        \n",
        "        # Store the transition in memory\n",
        "        reward_tensor = torch.tensor([reward], device=device)\n",
        "        memory.add(state, action, next_state_tensor, reward_tensor)\n",
        "        \n",
        "        # Move to the next state\n",
        "        state = next_state_tensor\n",
        "        \n",
        "        # Perform one step of the optimization\n",
        "        optimize_model()\n",
        "        \n",
        "    all_episodes_reward.append(total_reward)\n",
        "    \n",
        "    # Update the target network\n",
        "    if episode % target_update == 0:\n",
        "        target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PWoGbP-E64Au"
      },
      "source": [
        "The code below shows the agent's decision for a given observation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pu00m3IzQ_aN",
        "outputId": "5682bf55-4c7d-4b9d-cb7a-831c245cea3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled State: [ 6.9231093e-01  2.9461924e+38  4.0015143e-01 -1.1935672e+38]\n",
            "Chosen Action: 0\n"
          ]
        }
      ],
      "source": [
        "# Sample a random state from the environment\n",
        "random_state = env.observation_space.sample()\n",
        "state_tensor = torch.tensor([random_state], device=device, dtype=torch.float)\n",
        "\n",
        "# Choose action based on the randomly sampled state\n",
        "action = select_action(state_tensor)\n",
        "\n",
        "# Print the state and chosen action\n",
        "print(f\"Sampled State: {random_state}\")\n",
        "print(f\"Chosen Action: {action.item()}\")\n",
        "\n",
        "# Close the environment\n",
        "env.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-XtIQ0Rti1gm"
      },
      "source": [
        "## Task 2: Demonstrate the effectiveness of the RL agent"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OAwlfF3LBV0D"
      },
      "source": [
        "Here we run the agent again for 100 times, and append the reward for each round to a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRGBPweHXc7h",
        "outputId": "92d28009-0254-4559-cdf8-e9d2bdf0335f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:02<00:00, 47.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Reward over 100 episodes: 496.15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def run_episodes(env, policy_net, n_episodes=100):\n",
        "    rewards = []\n",
        "    for episode in tqdm(range(n_episodes)):\n",
        "        # Adjusting for the new env.reset() return values\n",
        "        state, _ = env.reset()\n",
        "        state = torch.tensor([state], device=device, dtype=torch.float)\n",
        "        episode_reward = 0\n",
        "        done = False\n",
        "        while not done:\n",
        "            action = select_action(state)\n",
        "            # Adjusting for the new env.step(action) return values\n",
        "            next_state, reward, done, _, _ = env.step(action.item())\n",
        "            episode_reward += reward\n",
        "            \n",
        "            if episode_reward > 500:  # Check if the reward exceeds 500\n",
        "                break  # Stop the episode and move on to the next one\n",
        "\n",
        "            # Prepare the next state for the next iteration\n",
        "            next_state = torch.tensor([next_state], device=device, dtype=torch.float)\n",
        "            state = next_state\n",
        "\n",
        "        rewards.append(episode_reward)\n",
        "    return rewards\n",
        "\n",
        "# Run episodes and collect rewards\n",
        "episode_rewards = run_episodes(env, policy_net, n_episodes=100)\n",
        "\n",
        "# Calculate and print the average reward\n",
        "average_reward = sum(episode_rewards) / len(episode_rewards)\n",
        "print(f\"Average Reward over 100 episodes: {average_reward}\")\n",
        "\n",
        "# Plotting the rewards\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(episode_rewards)\n",
        "plt.title('Cumulative Reward per Episode')\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Cumulative Reward')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg0DCT38lFA6"
      },
      "source": [
        "## Task 3: Render one episode played by the agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TASK 4: INSTRUCTION AND EXPLANATION"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In building our DQN model, we have implemented a Q-network along with a replay memory system, which follows the structure outlined in https://www.baeldung.com/cs/q-learning-vs-deep-q-learning-vs-deep-q-network."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Q-Network__: <br>\n",
        "The Q-network is a neural network which takes the state of the environment as input and outputs the expected reward for each possible action. This is the decision mkaing part of our mode. It starts with random guesses but gets better as it learns from the game through training.\n",
        "\n",
        "__Replay Memory__: <br>\n",
        "To help our Q-network learn, the replay memory is needed as it stores experiences (state, action, reward and new states) during teh game. Rather than learning from consecutive experiences as they happn, the model randomly samples from this memory, which can help to break any correlations in the sequence of experiences and leads to more stable learning."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By combining the 2, we ensure that our model learns from more than the most recent experience but benefits from past expereinces as well, leading to more effective learning. As it plays more games, it relies less on exploration and more on exploitation, which is known as epsilon decay, which was mentioned in the previous Q-learning implementation."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "References:\n",
        "In developing our RL agent, we referenced the PyTorch Tutoral on the implementation of DQN on both the Q-Network and Replay Memory. https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
